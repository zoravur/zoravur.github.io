<html>
  <head>
    <title>Spock: A Spoken Programming Language | Zoravur's Blog</title>
    <style>
      .subtitle {
        font-size: 1.2em; /* adjust size to your liking */
        font-weight: 600; /* semi-bold, change if you want it lighter or heavier */
        /* color: #666; gray color, adjust to match your theme */
        margin-top: 10px; /* space above the subtitle */
        margin-bottom: 10px; /* space below the subtitle */
        line-height: 1.4; /* improves readability */
        /* optional: gives it a slightly different look */
      }
    </style>
  </head>
  <body style="width: 650px">
    <h1>Spock: A Spoken Programming Language</h1>
    <p>August 2024</p>
    <p>
      In December 2023, I came up with the idea of a programming language you
      would be able to speak out loud, into your phone or computer, hands free.
      I thought it was an interesting idea for a couple of reasons:
    </p>
    <ul>
      <li>
        It would allow you to program on the go without a laptop, while still
        approaching threshold efficiency (130wpm output<sup
          >[<a href="#note1">1</a>]</sup
        >). Also, reducing the time from thought &rarr; action seemed like a
        powerful way to increase productivity.
      </li>
      <li>
        It would be an interesting experiment to see how voice programming would
        change software: Would being able to speak algorithms increase fluency
        with them? Would programming languages naturally become more terse and
        expressive, mirroring natural language? Would voice-written software
        libraries become spaghetti, or would the necessity of fitting the entire
        problem domain in your brain at once lead to more elegant solutions?
      </li>
      <li>
        There are many voice assistants which run code on your behalf, but none
        that are turing complete. A lang that allows you to communicate any task
        that a computer can conceivably do would be the ultimate in power and
        flexibility.
      </li>
    </ul>
    <p>
      At the time, I couldn't really pursue the idea due to other projects, nor
      had I really done any work in programming languages since second year, so
      I was forced to give up on the idea. Nonetheless, I briefly reviewed my
      course notes, and kept the idea on the back burner.
    </p>
    <p>
      In the past week, I've decided to pick the idea back up, and due to the
      beautifully written
      <a href="https://craftinginterpreters.com/">Crafting Interpreters</a>,
      along with the real time speech to text software
      <a href="https://github.com/ufal/whisper_streaming">whisper_streaming</a>,
      I've been able to make surprisingly swift progress toward making the
      language a reality. Here is some example code (euler1.spk):
    </p>
    <pre><code>
      define sum of multiples as lambda takes limit and divisor does begin
          define m as call quotient with limit and divisor
          define total as zero
          while m begin 
              set total as call sum with total and call product with m and divisor
              set m as call difference with m and one
          finish
          return total
      finish
      define total as call sum of multiples with 999 and 3
      set total as call sum with total and call sum of multiples with 999 and 5
      set total as call difference with total and call sum of multiples with 999 and 15
      print total
    </code></pre>
    <p>
      As you may have been able to guess by reading (either the code or the file
      name!), this code prints 233168, and is the solution to
      https://projecteuler.net/problem=1 (As there are no non-scalar data types,
      I stuck to more mathematical problems while building up the language.)
    </p>
    <p>
      Of note, this language consists of only numbers and easily pronounceable
      english words, and numbers are interchangeable with their word
      equivalents. Symbols can be multiple words, due to a carefully constructed
      grammar. There is no punctuation of any kind, and in fact, all punctuation
      and indentation is stripped during preprocessing. This leaves only a list
      of words, which are ideally 1-1 mapped to sounds.
    </p>
    <p>
      The language features themselves are similar to Lox, except this language
      is (to start) even simpler. Classes are missing, and regular functions are
      replaced with lambdas&mdash;given that lambdas are just functions that you
      can pass around, it seems perfectly reasonable to just replace functions
      with lambdas. Recursion is possible, although that's only due to an
      unintuitive bug (arguably)&mdash;I'm referring to the fact that the
      language is dynamically scoped, instead of lexically scoped.
    </p>
    <p>
      Classes and types are missing, and the interpreter itself is written in
      Python&mdash;which mean all I'm doing is translating Spock to a highly
      restricted subset of Python. This makes for a very slow and cumbersome
      language, for now.
    </p>
    <p>
      I hope to implement it as a bytecode vm as described in part 3 of Crafting
      Interpreters, written primarily in C, but also with a Foreign Function
      Interface to Python, that allows me to steal a lot of the useful code that
      already exists in Python libraries, for all different types of automation
      and machine learning.
    </p>
    <p>
      Other features I want to include are: garbage collection, a standard
      library, and static typing. I also want to add facilities to the
      interpreter to improve the developer experience (being forced to one shot
      your code without misspeaking even once is too difficult to be useful).
    </p>
    <p class="subtitle">Working with Voice</p>
    <p>
      Working with whisper_streaming and programming with voice has been
      interesting so far. It's not really natural for me yet, and I'm still
      agonizingly slow compared to how quickly I can write code with a keyboard
      and screen in front of me. Nonetheless, with very straightforward code, or
      when I've pre written the code and I'm just saying it into Whisper, I can
      definitely say it much faster than I could ever type it.
    </p>
    <p>
      If it were this simple though, then I'd be well on my way to making this
      idea a reality. One of the big hurdles, however, is
      <i>working around the limitations of Whisper. </i>
    </p>
    <p>
      Whisper is an audio-to-text model, designed mainly for the purposes of
      transcribing media. As such, it automatically performs a number of tricks
      and hallucinations that allow it to generate an unnaturally polished
      transcription of most of the media in its training set. The problem,
      however, is that Spock follows a different grammar to regular English, and
      Whisper alters the text stream in subtle but important ways. Here are a
      few hurdles that I've encountered:
    </p>
    <ul>
      <li>Mixing up similar sounding words: n, and, end</li>
      <li>
        Whisper removing repeated words: an earlier version of the grammar
        denoted argument lists using the words "left" and "right" for left and
        right parentheses. Some programs would have multiple "right" parentheses
        next to each other, which Whisper would then deduplicate, presumably
        because it's assuming that the speaker is stuttering, even when they are
        not.
      </li>
      <li>
        The infamous
        <a
          href="https://www.google.com/search?q=thank+you+for+watching+bug+chatgpt"
          >"Thank you for watching!" bug</a
        >, and random text in other languages: on silence, whisper transcribes a
        bunch of garbage (quite frequently), presumably because the subtitles it
        was trained on would contain some text that isn't matching the audio
        that it should. I imagine something similar to threshold probabilities
        would remedy this, but this is not easily configurable within Whisper.
      </li>
    </ul>
    <p>
      I've addressed the first two by modifying the grammar slightly, (notice,
      "begin" is normally paired with "end", but here it is paired with
      "finish", and instead of left and right, we have lists joined with the
      word "and". The logical AND function is consequently called conj), but the
      garbage transcription is something I'm still dealing with.
    </p>
    <p>
      One idea that I had for improving the annoying situations where the
      transcription fails is fine-tuning&mdash;by providing labelled examples of
      programs, I could greatly improve Whisper's ability to detect the words
      that are common in the language. Hopefully this would deal with the
      garbage transcription as well, as some of these examples may contain long
      pauses in which I'm thinking about the next line of code to write.
    </p>
    <p>
      I have more to say about the finetuning problem (it would fix the grammar
      of the language, possible methods of generating data / programs), but I
      think I'll continue this part of the discussion in a future post.
    </p>
    <p class="subtitle">The far future.</p>
    <p>
      With a large repository of language data, one may see spoken programming
      languages diverge from how English is spoken (though cross pollination
      would always exist). Perhaps, like natural language, language constructs
      could be assigned to shorter and shorter sounds depending on how
      frequently they are used. One could maybe group syntax based on the pauses
      between words, allowing one to generate mathematical expressions by saying
      things in exactly the right way. Maybe one day, we'll all be talking to
      computers &mdash;
      <a href="https://www.youtube.com/watch?v=Drr6_zikuZQ">like in Star Trek</a
      >: perfectly logical and precise, not flaky, unreliable, and too-emotional
      LLMs.
    </p>
    <h2>Notes</h2>
    <ol>
      <li id="note1">
        The average speaking rate is 100-130 wpm according to Google, and I know
        people personally that type 130+ wpm, so it seems that speaking is
        comparable to typing in terms of max speed. Typing may win on an
        increased character set, but a fast speaker can easily go 160 wpm, so my
        not so scientific guess is that they're pretty comparable. Both, of
        course, are ultimately limited by the speed of thought.
      </li>
    </ol>
  </body>
</html>
